{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes - Análise de Sentimento\n",
    "\n",
    "Para essa atividade vamos gerar uma modelo de análise de sentimento em inglês baseado em reviews retirados de 3 sites: Amazon, IMDb e Yelp. Essa base está disponível [neste link](https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences). Mais detalhes podem ser encontrados no link ou no artigo de referência: *From Group to Individual Labels using Deep Features', Kotzias et. al,. KDD 2015*. \n",
    "\n",
    "A base possui um texto e para cada texto um sentimento sobre o conteúdo abordado no texto. Os sentimentos podem ser positivos (1) ou negativos (2). Foram coletados em média 500 textos para cada sentimento em cada base. \n",
    "\n",
    "A atividade consiste em construir uma modelo de aprendizagem para análise de sentimento em inglês utilizando o Naive Bayes. O primeiro passo foi carregar o Dataset de forma apropriada e em seguida construir a matriz de entrada para nosso algoritmo. As etapas do exercício juntamente com o que deve ser feito está descrito a seguir. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando o Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_amazon = pd.read_csv(\"../datasets/sentimentanalysis/amazon_cells_labelled.txt\", \n",
    "                        sep=\"\\t\", header=None, names=['Text','Sentiment'])\n",
    "df_imdb = pd.read_csv(\"../datasets/sentimentanalysis/imdb_labelled.txt\", \n",
    "                        sep=\"\\t\", header=None, names=['Text','Sentiment'])\n",
    "df_yelp = pd.read_csv(\"../datasets/sentimentanalysis/yelp_labelled.txt\", \n",
    "                        sep=\"\\t\", header=None, names=['Text','Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon dataset (1000, 2)\n",
      "IMDb dataset (748, 2)\n",
      "Yelp dataset (1000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Amazon dataset %s\" % str(df_amazon.shape))\n",
    "print(\"IMDb dataset %s\" % str(df_imdb.shape))\n",
    "print(\"Yelp dataset %s\" % str(df_yelp.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2748, 2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_frames = [df_amazon, df_imdb, df_yelp]\n",
    "\n",
    "df_final_dataset = pd.concat(join_frames)\n",
    "\n",
    "df_final_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construindo a base de dados\n",
    "\n",
    "A base de dados possui 2748 textos que foram classificados em dois sentimentos: negativo (0) e positivo (1). Construa uma base de dados apropriada para os testes. Divida a base em treino e teste (80% para treino e 20% para teste). A base de treinamento será utilizado para a construção do modelo e a de teste para o teste final do modelo construído. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_final_dataset['Text'], \n",
    "                                                    df_final_dataset['Sentiment'], \n",
    "                                                    random_state=1,\n",
    "                                                    test_size=0.2\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the total set: 2748\n",
      "Number of rows in the training set: 2198\n",
      "Number of rows in the test set: 550\n"
     ]
    }
   ],
   "source": [
    "print('Number of rows in the total set: {}'.format(df_final_dataset.shape[0]))\n",
    "print('Number of rows in the training set: {}'.format(X_train.shape[0]))\n",
    "print('Number of rows in the test set: {}'.format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construindo o Bag of Words\n",
    "\n",
    "Construa o Bag of Words para a base de treinamento. Para isso, utilize o método CountVectorizer como mostrado a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "count_vector = CountVectorizer()\n",
    "count_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O `CountVectorizer` permite construir o array que serve de entrada para os modelos de aprendizagem. O código a seguir, visualiza o array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2198, 4581)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = count_vector.fit_transform(X_train)\n",
    "training_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi gerada uma matriz de 2198 linhas (os textos) e 4581 colunas (as palavras). Devemos fazer o mesmo com a base de teste. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(550, 4581)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data = count_vector.transform(X_test)\n",
    "testing_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi gerada uma matriz com 550 linhas e 4581 colunas também. `training_data` e `testing_data` são as estruturas que devem ser utilizadas no modelo Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atividade 1\n",
    "\n",
    "Implemente um modelo Naive Bayes para a base gerada. Utilize validação cruzada de 5 folds na base de treinamento e em seguida teste o modelo gerado na base de testes. Reporte a acurácia resultante da validação cruzada e da base de testes. Teste os 3 tipos de Naive Bayes presentes no `scikit-learn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc do MultinomialNB (treino): 0.813474 \n",
      "Acc do MultinomialNB (teste): 0.812727 \n",
      "\n",
      "Acc do GaussianNB (treino): 0.653311 \n",
      "Acc do GaussianNB (teste): 0.645455 \n",
      "\n",
      "Acc do BernoulliNB (treino): 0.802111 \n",
      "Acc do BernoulliNB (teste): 0.800000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "naive1 = MultinomialNB()\n",
    "naive2 = GaussianNB()\n",
    "naive3 = BernoulliNB()\n",
    "\n",
    "algorithms = [naive1, naive2, naive3]\n",
    "\n",
    "for algo in algorithms:\n",
    "    scores = cross_val_score(algo, training_data.toarray(), y_train, cv=5, scoring='accuracy')\n",
    "    score_mean = scores.mean()\n",
    "    print(\"Acc do %s (treino): %f \" % (algo.__class__.__name__, score_mean))\n",
    "    \n",
    "    algo.fit(training_data.toarray(), y_train)\n",
    "    score_test = algo.score(testing_data.toarray(), y_test)\n",
    "    print(\"Acc do %s (teste): %f \" % (algo.__class__.__name__, score_test))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sendo assim, o MultinomialNB foi o melhor modelo utilizando validação cruzada de 5 folds. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atividade 2\n",
    "\n",
    "O Naive Bayes em si não tem muitos parâmetros para ajustar. No entanto, podemos ajustar no pré-processamento. Quando utilizamos a classe `CountVectorizer` podemos utilizar uma série de técnicas de pré-processamento para melhorar os dados de entrada do modelo. \n",
    "\n",
    "Pesquise sobre o `CountVectorizer` e modifique os parâmetros `default` para gerar dados melhores e, consequentemente, um modelo melhor do que o construído na Atividade 1. Reporte seus resultados na validação cruzada e nos testes. Utilize somente o tipo de Naive Bayes que teve melhor resultado na atividade 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_final_dataset['Text'], \n",
    "                                                    df_final_dataset['Sentiment'], \n",
    "                                                    random_state=1,\n",
    "                                                    test_size=0.3\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the total set: 2748\n",
      "Number of rows in the training set: 1923\n",
      "Number of rows in the test set: 825\n"
     ]
    }
   ],
   "source": [
    "print('Number of rows in the total set: {}'.format(df_final_dataset.shape[0]))\n",
    "print('Number of rows in the training set: {}'.format(X_train.shape[0]))\n",
    "print('Number of rows in the test set: {}'.format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para essa atividade, precisamos gerar novamente nossa matriz de entrada para os modelos. Como pedido na questão, o método `CountVectorizer` permite transformar os textos nessa tabela. No entanto, no exemplo apresentado anteriormente não mudamos nenhuma das informações padrões. Vamos mudar algumas coisas e tentar chegar em um modelo melhor que o construído. \n",
    "\n",
    "Nosso melhor exemplo foi obtido utilizando o `MultinomialNB` com acurácia de `0.813474`. Vamos trabalhar somente com esse modelo para essa questão. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer\n",
    "\n",
    "Informações sobre o `CountVectorizer` podem ser encontrados [neste link](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) da documentação do `scikit-learn`.\n",
    "\n",
    "Como já foi dito anteriormente, na classificação de textos nossos atributos são formados pelas palavras que compõe o conjunto de textos trabalhados. No exemplo trabalhado, essas colunas consistem em todas as palavras. No entanto, nem sempre precisamos de todas palavras. É fácil perceber que existem palavras que não fornencem nenhuma informação para a construção do modelo de classificação. \n",
    "\n",
    "Sendo assim, nossa primeira alteração no modelo é limitar o número de atributos através do atributo `max_features`. Vamos ver o que isso implica na acurácia. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Original sem alterações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do Vocabulário 4265 \n",
      "Acc do MultinomialNB (treino): 0.802111 \n",
      "Acc do MultinomialNB (teste) 0.787879 \n"
     ]
    }
   ],
   "source": [
    "count_vector = CountVectorizer()\n",
    "training_data = count_vector.fit_transform(X_train)\n",
    "testing_data = count_vector.transform(X_test)\n",
    "\n",
    "print(\"Tamanho do Vocabulário %i \" % (len(count_vector.vocabulary_.keys())))\n",
    "\n",
    "algo_final = MultinomialNB()\n",
    "\n",
    "scores = cross_val_score(algo_final, training_data.toarray(), y_train, cv=5, scoring='accuracy')\n",
    "print(\"Acc do %s (treino): %f \" % (algo_final.__class__.__name__, score_mean))\n",
    "\n",
    "algo_final.fit(training_data.toarray(), y_train)\n",
    "score_test = algo_final.score(testing_data.toarray(), y_test)\n",
    "print(\"Acc do %s (teste) %f \" % (algo_final.__class__.__name__, score_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo com as modificações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do Vocabulário 300 \n",
      "Acc do MultinomialNB (treino): 0.802111 \n",
      "Acc do MultinomialNB (teste) 0.744242 \n"
     ]
    }
   ],
   "source": [
    "count_vector = CountVectorizer(max_features=300, \n",
    "                               ngram_range=(1,2), \n",
    "                               stop_words=text.ENGLISH_STOP_WORDS,\n",
    "                               analyzer='word',\n",
    "                               max_df=0.8,\n",
    "                               min_df=5)\n",
    "\n",
    "training_data = count_vector.fit_transform(X_train)\n",
    "testing_data = count_vector.transform(X_test)\n",
    "\n",
    "print(\"Tamanho do Vocabulário %i \" % (len(count_vector.vocabulary_.keys())))\n",
    "\n",
    "algo_final = MultinomialNB()\n",
    "\n",
    "scores = cross_val_score(algo_final, training_data.toarray(), y_train, cv=5, scoring='accuracy')\n",
    "print(\"Acc do %s (treino): %f \" % (algo_final.__class__.__name__, score_mean))\n",
    "\n",
    "algo_final.fit(training_data.toarray(), y_train)\n",
    "score_test = algo_final.score(testing_data.toarray(), y_test)\n",
    "print(\"Acc do %s (teste) %f \" % (algo_final.__class__.__name__, score_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 : 25\n",
      "20 : 8\n",
      "absolutely : 13\n",
      "acting : 30\n",
      "actors : 13\n",
      "actually : 12\n",
      "amazing : 27\n",
      "area : 8\n",
      "art : 12\n",
      "atmosphere : 10\n",
      "avoid : 15\n",
      "away : 9\n",
      "awesome : 13\n",
      "awful : 18\n",
      "bad : 70\n",
      "battery : 32\n",
      "battery life : 9\n",
      "beautiful : 10\n",
      "believe : 7\n",
      "best : 58\n",
      "better : 44\n",
      "big : 15\n",
      "bit : 13\n",
      "black : 15\n",
      "bland : 11\n",
      "bluetooth : 16\n",
      "boring : 9\n",
      "bought : 15\n",
      "breakfast : 9\n",
      "burger : 10\n",
      "buy : 16\n",
      "calls : 10\n",
      "came : 22\n",
      "camera : 13\n",
      "car : 15\n",
      "care : 9\n",
      "case : 28\n",
      "cast : 14\n",
      "cell : 11\n",
      "certainly : 10\n",
      "character : 17\n",
      "characters : 27\n",
      "charge : 12\n",
      "charger : 13\n",
      "cheap : 15\n",
      "chicken : 15\n",
      "clear : 10\n",
      "cold : 8\n",
      "come : 10\n",
      "comfortable : 13\n",
      "coming : 12\n",
      "completely : 11\n",
      "cool : 14\n",
      "couldn : 12\n",
      "crap : 9\n",
      "customer : 12\n",
      "customer service : 12\n",
      "day : 13\n",
      "deal : 11\n",
      "definitely : 24\n",
      "delicious : 10\n",
      "design : 10\n",
      "device : 9\n",
      "dialogue : 11\n",
      "did : 33\n",
      "didn : 32\n",
      "different : 11\n",
      "director : 10\n",
      "disappointed : 28\n",
      "disappointing : 9\n",
      "disappointment : 9\n",
      "does : 27\n",
      "doesn : 22\n",
      "don : 48\n",
      "don waste : 10\n",
      "dropped : 8\n",
      "ear : 20\n",
      "easy : 14\n",
      "eat : 11\n",
      "effects : 9\n",
      "end : 13\n",
      "ending : 10\n",
      "enjoy : 8\n",
      "enjoyed : 12\n",
      "especially : 13\n",
      "excellent : 34\n",
      "expect : 10\n",
      "expected : 8\n",
      "experience : 21\n",
      "extremely : 10\n",
      "fact : 10\n",
      "family : 15\n",
      "fantastic : 13\n",
      "far : 21\n",
      "fast : 10\n",
      "feel : 12\n",
      "feeling : 9\n",
      "felt : 9\n",
      "film : 129\n",
      "films : 23\n",
      "finally : 8\n",
      "fine : 17\n",
      "fit : 10\n",
      "fits : 9\n",
      "flavor : 13\n",
      "food : 87\n",
      "fresh : 9\n",
      "friendly : 22\n",
      "funny : 17\n",
      "glad : 8\n",
      "going : 29\n",
      "good : 163\n",
      "got : 32\n",
      "great : 149\n",
      "hands : 10\n",
      "happy : 17\n",
      "hard : 14\n",
      "having : 8\n",
      "headset : 34\n",
      "hear : 10\n",
      "high : 9\n",
      "highly : 21\n",
      "highly recommend : 11\n",
      "home : 8\n",
      "horrible : 13\n",
      "hot : 8\n",
      "hour : 11\n",
      "hours : 9\n",
      "huge : 8\n",
      "impressed : 14\n",
      "inside : 8\n",
      "interesting : 9\n",
      "item : 18\n",
      "job : 9\n",
      "just : 92\n",
      "kids : 9\n",
      "kind : 12\n",
      "know : 22\n",
      "left : 9\n",
      "life : 21\n",
      "like : 92\n",
      "liked : 9\n",
      "line : 13\n",
      "little : 24\n",
      "ll : 14\n",
      "long : 16\n",
      "look : 23\n",
      "looks : 11\n",
      "lot : 18\n",
      "love : 41\n",
      "loved : 14\n",
      "low : 13\n",
      "lunch : 8\n",
      "make : 31\n",
      "makes : 12\n",
      "man : 9\n",
      "meat : 8\n",
      "mediocre : 9\n",
      "menu : 9\n",
      "mess : 11\n",
      "minutes : 26\n",
      "money : 24\n",
      "months : 10\n",
      "motorola : 8\n",
      "movie : 125\n",
      "movies : 23\n",
      "music : 16\n",
      "need : 9\n",
      "new : 24\n",
      "nice : 39\n",
      "night : 10\n",
      "oh : 8\n",
      "old : 15\n",
      "ordered : 8\n",
      "overall : 10\n",
      "pay : 8\n",
      "people : 29\n",
      "perfect : 13\n",
      "perfectly : 10\n",
      "performance : 8\n",
      "phone : 126\n",
      "picture : 8\n",
      "piece : 19\n",
      "pizza : 10\n",
      "place : 87\n",
      "places : 7\n",
      "played : 9\n",
      "playing : 7\n",
      "pleased : 7\n",
      "plot : 22\n",
      "plug : 7\n",
      "poor : 21\n",
      "predictable : 8\n",
      "pretty : 30\n",
      "price : 25\n",
      "priced : 7\n",
      "prices : 7\n",
      "probably : 14\n",
      "problem : 11\n",
      "problems : 13\n",
      "product : 40\n",
      "purchase : 13\n",
      "quality : 42\n",
      "quite : 18\n",
      "real : 23\n",
      "really : 76\n",
      "received : 8\n",
      "reception : 9\n",
      "recommend : 38\n",
      "recommended : 10\n",
      "restaurant : 14\n",
      "return : 10\n",
      "right : 24\n",
      "said : 15\n",
      "salad : 9\n",
      "sauce : 8\n",
      "saw : 9\n",
      "say : 26\n",
      "scene : 13\n",
      "scenes : 16\n",
      "screen : 16\n",
      "script : 18\n",
      "seen : 22\n",
      "selection : 8\n",
      "seriously : 7\n",
      "server : 9\n",
      "service : 74\n",
      "short : 11\n",
      "simply : 9\n",
      "slow : 13\n",
      "small : 13\n",
      "sound : 35\n",
      "special : 14\n",
      "staff : 13\n",
      "star : 8\n",
      "stars : 12\n",
      "started : 9\n",
      "steak : 10\n",
      "story : 22\n",
      "stupid : 14\n",
      "sucks : 14\n",
      "super : 9\n",
      "superb : 7\n",
      "sure : 13\n",
      "talk : 13\n",
      "taste : 8\n",
      "tasty : 9\n",
      "terrible : 22\n",
      "thing : 26\n",
      "things : 16\n",
      "think : 29\n",
      "thought : 12\n",
      "time : 83\n",
      "times : 20\n",
      "today : 8\n",
      "totally : 14\n",
      "tried : 10\n",
      "truly : 10\n",
      "try : 14\n",
      "turn : 8\n",
      "tv : 8\n",
      "understand : 9\n",
      "unfortunately : 9\n",
      "use : 37\n",
      "used : 15\n",
      "using : 11\n",
      "ve : 52\n",
      "ve seen : 9\n",
      "vegas : 17\n",
      "voice : 8\n",
      "wait : 13\n",
      "waited : 8\n",
      "want : 21\n",
      "wasn : 21\n",
      "waste : 27\n",
      "waste money : 9\n",
      "waste time : 15\n",
      "wasted : 9\n",
      "watch : 14\n",
      "watched : 10\n",
      "watching : 18\n",
      "way : 28\n",
      "went : 18\n",
      "white : 10\n",
      "won : 19\n",
      "wonderful : 21\n",
      "work : 45\n",
      "worked : 19\n",
      "working : 8\n",
      "works : 39\n",
      "works great : 15\n",
      "world : 7\n",
      "worse : 8\n",
      "worst : 29\n",
      "worth : 17\n",
      "wouldn : 7\n",
      "writing : 11\n",
      "wrong : 7\n",
      "year : 14\n",
      "years : 19\n"
     ]
    }
   ],
   "source": [
    "array_count = np.asarray(training_data.sum(axis=0))[0]\n",
    "features = count_vector.get_feature_names()\n",
    "\n",
    "for e in  zip(features, array_count):\n",
    "    print(\"%s : %i\" % (e[0], e[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
