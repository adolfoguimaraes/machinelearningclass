{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizado Supervisionado\n",
    "\n",
    "## Exercício 02\n",
    "\n",
    "### Atividade 01\n",
    "\n",
    "Finalize a construção da árvore de decisão a seguir. Utilize os conceitos de Entropia e Ganho de Informação vistos no tutorial de árvore de decisão.\n",
    "\n",
    "<img src=\"http://www.data2learning.com/machinelearning/images_notebook/arvoredecisao_02.png\" width=\"60%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O conjunto *S* passa ser agora, no caso de chuvoso, $ S = {D4, D5, D6, D10, D14}$ que são divididos em $[3+, 2-]$.\n",
    "\n",
    "Para finalizar a árvore, vamos trabalhar com o caso *Chuvoso*.\n",
    "\n",
    "O primeiro passo é calcular a entropia de S ($E(S)$):\n",
    "\n",
    "$E = \\sum_{i}^{c}{-p_i\\log_2{p_i}} = -\\frac{3}{5}*\\log_2{\\frac{3}{5}} - \\frac{2}{5}*\\log_2{\\frac{2}{5}} = 0.971$\n",
    "\n",
    "Com o valor da Entropia de $S$, calculamos o $GI$ para cada um dos atributos restantes: Umidade, Temperatura e Vento.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O Atributo Umidade [Alta, Normal]\n",
    "\n",
    "O atributo umidade está dividido da seguinte forma na base de treinamento: \n",
    "\n",
    "* Alta: $\\frac{2}{5}$ onde $[1+, 1-]$ \n",
    "\n",
    "\n",
    "* Normal: $\\frac{3}{5}$ onde $[2+, 1-]$\n",
    "\n",
    "\n",
    "Vamos calcular:\n",
    "\n",
    "$- \\sum_{v \\in Valores(A)}{\\frac{S_v}{S}E(S_v)} = -\\frac{2}{5}*E(S_{Alta}) - \\frac{3}{5}*E(S_{Normal})$\n",
    "\n",
    "Calculando a entropia de cada atributo temos:\n",
    "\n",
    "$E(S_{Alta}) = - \\frac{1}{2}*log_2{\\frac{1}{2}} - \\frac{2}{2}*log_2{\\frac{1}{2}} = 1$\n",
    "\n",
    "$E(S_{Normal}) = - \\frac{2}{3}*log_2{\\frac{2}{3}} - \\frac{1}{3}*log_2{\\frac{1}{3}} = 0.918$\n",
    "\n",
    "\n",
    "Agora podemos calcular o Ganho de Informação:\n",
    "\n",
    "$- \\sum_{v \\in Valores(A)}{\\frac{S_v}{S}E(S_v)} = -\\frac{2}{5}*E(S_{Alta}) - \\frac{3}{5}*E(S_{Normal})$\n",
    "\n",
    "$- \\sum_{v \\in Valores(A)}{\\frac{S_v}{S}E(S_v)} = -\\frac{2}{5}*1 - \\frac{3}{5}*0.918 = -0.951$\n",
    "\n",
    "Por fim, temos que o GI de informação para o atributo Umidade é:\n",
    "\n",
    "$GI(S,A) = E(S) - \\sum_{v \\in Valores(A)}{\\frac{S_v}{S}E(S_v)}$\n",
    "\n",
    "$GI(S,A) = 0.971 - 0.951 = 0.02$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atributo Temperatura [Quente, Intermediária, Fria]\n",
    "\n",
    "O atributo Temperatura está dividido da seguinte forma na base de treinamento: \n",
    "\n",
    "* Quente: $\\frac{0}{5}$ onde $[0+, 0-]$ \n",
    "\n",
    "\n",
    "* Intermediária: $\\frac{3}{5}$ onde $[2+, 1-]$\n",
    "\n",
    "\n",
    "* Fria: $\\frac{2}{5}$ onde $[1+, 1-]$ \n",
    "\n",
    "É fácil definir as entropiais individiuais:\n",
    "\n",
    "$E_(S_{Quente}) = 0$\n",
    "\n",
    "$E_(S_{Intermediaria}) = - \\frac{2}{3}*log_2{\\frac{2}{3}} - \\frac{1}{3}*log_2{\\frac{1}{3}} = 0.918$\n",
    "\n",
    "$E_(S_{Fria}) = 1$\n",
    "\n",
    "Vamos calcular o Ganho de Informação:\n",
    "\n",
    "$- \\sum_{v \\in Valores(A)}{\\frac{S_v}{S}E(S_v)} = -\\frac{0}{5}*E(S_{Quente}) - \\frac{3}{5}*E(S_{Intermediaria}) - \n",
    "\\frac{2}{5}*E(S_{Fria})$\n",
    "\n",
    "$- \\sum_{v \\in Valores(A)}{\\frac{S_v}{S}E(S_v)} = -\\frac{0}{5}*0 - \\frac{3}{5}0.918 - \\frac{2}{5}*1 = 0.951$\n",
    "\n",
    "Por fim, temos que o GI de informação para o atributo Temperatura é:\n",
    "\n",
    "$GI(S,A) = E(S) - \\sum_{v \\in Valores(A)}{\\frac{S_v}{S}E(S_v)}$\n",
    "\n",
    "$GI(S,A) = 0.971 - 0.951 = 0.02$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atributo Vento [Fraco, Forte]\n",
    "\n",
    "O atributo Vento está dividido da seguinte forma na base de treinamento: \n",
    "\n",
    "* Fraco: $\\frac{3}{5}$ onde $[3+, 0-]$ \n",
    "\n",
    "* Forte: $\\frac{2}{5}$ onde $[0+, 2-]$\n",
    "\n",
    "É fácil definir as entropiais individiuais:\n",
    "\n",
    "$E_(S_{Fraco}) = 0$\n",
    "\n",
    "$E_(S_{Forte}) = 0$\n",
    "\n",
    "Vamos calcular o Ganho de Informação:\n",
    "\n",
    "$- \\sum_{v \\in Valores(A)}{\\frac{S_v}{S}E(S_v)} = -\\frac{3}{5}*E(S_{Fraco}) - \\frac{2}{5}*E(S_{Forte})$\n",
    "\n",
    "$- \\sum_{v \\in Valores(A)}{\\frac{S_v}{S}E(S_v)} = -\\frac{3}{5}*0 - \\frac{2}{5}*0 = 0$\n",
    "\n",
    "Por fim, temos que o GI de informação para o atributo Vento é:\n",
    "\n",
    "$GI(S,A) = E(S) - \\sum_{v \\in Valores(A)}{\\frac{S_v}{S}E(S_v)}$\n",
    "\n",
    "$GI(S,A) = 0.971 - 0 = 0.971$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sendo assim, temos:\n",
    "\n",
    "$GI(S, Umidade) = 0,02$\n",
    "\n",
    "$GI(S, Temperatura) = 0,02$\n",
    "\n",
    "$GI(S, Vento) = 0,971$\n",
    "\n",
    "Logo, o atributo com maior ganho de informaçõa é o `Vento`. É ele que devemos utilizar para finalizar a construção da árvore. \n",
    "\n",
    "A árvore final fica: \n",
    "\n",
    "<img src=\"http://www.data2learning.com/machinelearning/images_notebook/decision_tree_resposta.png\" width=\"60%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atividade 02\n",
    "\n",
    "Considere a base de dados a seguir: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Idade</th>\n",
       "      <th>Salario</th>\n",
       "      <th>SuperiorCompleto</th>\n",
       "      <th>Dependentes</th>\n",
       "      <th>Atrasou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MENOR30</td>\n",
       "      <td>ALTO</td>\n",
       "      <td>NAO</td>\n",
       "      <td>NAO</td>\n",
       "      <td>NAO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MENOR30</td>\n",
       "      <td>ALTO</td>\n",
       "      <td>NAO</td>\n",
       "      <td>SIM</td>\n",
       "      <td>NAO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3140</td>\n",
       "      <td>ALTO</td>\n",
       "      <td>NAO</td>\n",
       "      <td>NAO</td>\n",
       "      <td>SIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAIOR40</td>\n",
       "      <td>MEDIO</td>\n",
       "      <td>NAO</td>\n",
       "      <td>NAO</td>\n",
       "      <td>SIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MAIOR40</td>\n",
       "      <td>BAIXO</td>\n",
       "      <td>SIM</td>\n",
       "      <td>NAO</td>\n",
       "      <td>SIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MAIOR40</td>\n",
       "      <td>BAIXO</td>\n",
       "      <td>SIM</td>\n",
       "      <td>SIM</td>\n",
       "      <td>NAO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3140</td>\n",
       "      <td>BAIXO</td>\n",
       "      <td>SIM</td>\n",
       "      <td>SIM</td>\n",
       "      <td>SIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MENOR30</td>\n",
       "      <td>MEDIO</td>\n",
       "      <td>NAO</td>\n",
       "      <td>NAO</td>\n",
       "      <td>NAO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MENOR30</td>\n",
       "      <td>BAIXO</td>\n",
       "      <td>SIM</td>\n",
       "      <td>SIM</td>\n",
       "      <td>SIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MAIOR40</td>\n",
       "      <td>MEDIO</td>\n",
       "      <td>SIM</td>\n",
       "      <td>NAO</td>\n",
       "      <td>SIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MENOR30</td>\n",
       "      <td>MEDIO</td>\n",
       "      <td>SIM</td>\n",
       "      <td>SIM</td>\n",
       "      <td>SIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3140</td>\n",
       "      <td>MEDIO</td>\n",
       "      <td>NAO</td>\n",
       "      <td>SIM</td>\n",
       "      <td>SIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3140</td>\n",
       "      <td>ALTO</td>\n",
       "      <td>SIM</td>\n",
       "      <td>NAO</td>\n",
       "      <td>SIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MAIOR40</td>\n",
       "      <td>MEDIO</td>\n",
       "      <td>NAO</td>\n",
       "      <td>SIM</td>\n",
       "      <td>NAO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Idade Salario SuperiorCompleto Dependentes Atrasou\n",
       "0   MENOR30    ALTO              NAO         NAO     NAO\n",
       "1   MENOR30    ALTO              NAO         SIM     NAO\n",
       "2      3140    ALTO              NAO         NAO     SIM\n",
       "3   MAIOR40   MEDIO              NAO         NAO     SIM\n",
       "4   MAIOR40   BAIXO              SIM         NAO     SIM\n",
       "5   MAIOR40   BAIXO              SIM         SIM     NAO\n",
       "6      3140   BAIXO              SIM         SIM     SIM\n",
       "7   MENOR30   MEDIO              NAO         NAO     NAO\n",
       "8   MENOR30   BAIXO              SIM         SIM     SIM\n",
       "9   MAIOR40   MEDIO              SIM         NAO     SIM\n",
       "10  MENOR30   MEDIO              SIM         SIM     SIM\n",
       "11     3140   MEDIO              NAO         SIM     SIM\n",
       "12     3140    ALTO              SIM         NAO     SIM\n",
       "13  MAIOR40   MEDIO              NAO         SIM     NAO"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "data = pandas.read_csv('http://www.data2learning.com/machinelearning/datasets/base_dt.dat')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores para o atributo Idade:  ['3140', 'MAIOR40', 'MENOR30']\n",
      "Valores para o atributo Salário:  [' ALTO', ' BAIXO', ' MEDIO']\n",
      "Valores para o atributo SuperiorCompleto:  [' NAO', ' SIM']\n",
      "Valores para o atributo Dependentes:  [' NAO', ' SIM']\n",
      "Valores para o atributo Atrasou:  [' NAO', ' SIM']\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le_P = preprocessing.LabelEncoder() # Panorama\n",
    "le_T = preprocessing.LabelEncoder() # Temperatura\n",
    "le_U = preprocessing.LabelEncoder() # Umidade\n",
    "le_V = preprocessing.LabelEncoder() # Vento\n",
    "le_J = preprocessing.LabelEncoder() # Jogar\n",
    "\n",
    "# Transforma os atributos de string em numéricos. Os números são atribuídos de acordo com a posição do label \n",
    "# na lista que está sendo impressa.\n",
    "data.Idade = le_P.fit_transform(data.Idade)\n",
    "print(\"Valores para o atributo Idade: \", list(le_P.classes_))\n",
    "\n",
    "data.Salario = le_T.fit_transform(data.Salario)\n",
    "print(\"Valores para o atributo Salário: \", list(le_T.classes_))\n",
    "\n",
    "data.SuperiorCompleto = le_U.fit_transform(data.SuperiorCompleto)\n",
    "print(\"Valores para o atributo SuperiorCompleto: \", list(le_U.classes_))\n",
    "\n",
    "data.Dependentes = le_V.fit_transform(data.Dependentes)\n",
    "print(\"Valores para o atributo Dependentes: \", list(le_V.classes_))\n",
    "\n",
    "data.Atrasou = le_J.fit_transform(data.Atrasou)\n",
    "print(\"Valores para o atributo Atrasou: \", list(le_J.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A base analisa algumas informações sobre clientes de um plano de saúde e analisa se eles atrasaram ou não o pagamento da mensalidade do plano. Deseja-se construir um modelo de predição baseado em árvore de decisão. O primeiro passo é determinar qual o atributo raiz da árvore de decisão. Calcule qual o melhor atributo para a raiz da árvore sabendo que que o Ganho de Informação (GI) do atributo Salário é 0.03 e o do atributo SuperiorCompleto é 0.152."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sabendo que o cálculo do GI é dado por: \n",
    "\n",
    "$GI(S,A) = E(S) - \\sum_{v \\in Valores(A)}{\\frac{S_v}{S}E(S_v)}$, \n",
    "\n",
    "onde S é o conjunto de treinamento que vai ser dividido e A é o atributo a ser considerado. \n",
    "\n",
    "O primeiro passo é calcular E(S).\n",
    "\n",
    "$E(S) = -\\frac{9}{14}\\log_2{\\frac{9}{14}} - \\frac{5}{14}\\log_2{\\frac{5}{14}} = 0.940$\n",
    "\n",
    "\n",
    "Agora vamos calcular a entropia em cada um dos atributos restantes para que possamos analisar o ganho de informação.\n",
    "\n",
    "### `Atributo: Dependentes`\n",
    "\n",
    "O primeiro atributo a ser analisado será **Dependentes** (que pode receber dois valores: Sim ou Não). Como visto, $S$ possui 9 instâncias positivas e 5 instâncias negativas (classe para classificação). Considere também que 4 dos exemplos positivos e 3 dos exemplos negativos são associados a ter dependentes. Além disso, 2 exemplos negativos e 5 exemplos positivos estão associados a não ter dependentes.\n",
    "\n",
    "Vamos calcular o ganho de informação ao selecionar o  atributo Dependentes para a raiz de uma árvore de decisão. Vejamos como é feito o cálculo, utilizando as definições matemáticas apresentadas no material didático.\n",
    "\n",
    "**Cálculo**\n",
    "\n",
    "O conjunto S está dividido da seguinte forma: $S = [9+, 5-]$ e a divisão de acordo com o atributo `Dependentes` é dada por:\n",
    "\n",
    "$S_{Sim} \\leftarrow [4+, 3-]$\n",
    "\n",
    "$S_{Não} \\leftarrow [5+, 2-]$\n",
    "\n",
    "Como visto, o atributo Dependentes possui dois valores e devemos calcular a entropia para cada um desses atributos: \n",
    "\n",
    "$E(S_{sim}) = -\\frac{4}{7}\\log_2{\\frac{4}{7}} - \\frac{3}{7}\\log_2{\\frac{3}{7}} = 0.985$\n",
    "\n",
    "$E(S_{nao}) = -\\frac{5}{7}\\log_2{\\frac{5}{7}} - \\frac{2}{7}\\log_2{\\frac{2}{7}} = 0.863$\n",
    "\n",
    "Com isso podemos calcular: \n",
    "\n",
    "$- \\sum_{v \\in Valores(A)}{\\frac{S_v}{S}E(S_v)}$\n",
    "\n",
    "$- \\frac{7}{14}*0.985 - \\frac{7}{14}*0.863 = -0.924$\n",
    "\n",
    "Por fim, temos que  o Ganho de Informação é: \n",
    "\n",
    "$GI(S,A) = E(S) - \\sum_{v \\in Valores(A)}{\\frac{S_v}{S}E(S_v)} = 0.940 - 0.924 = 0.016$\n",
    "\n",
    "### `Atributo: Idade`\n",
    "\n",
    "Vamos trabalhar da mesma forma que fizemos o atributo anterior. O conjunto S está dividido da seguinte forma: $S = [9+, 5-]$ e a divisão de acordo com o atributo `Idade` é dada por:\n",
    "\n",
    "$S_{MENOR30} \\leftarrow [2+, 3-]$\n",
    "\n",
    "$S_{3140} \\leftarrow [4+, 0-]$\n",
    "\n",
    "$S_{MAIOR40} \\leftarrow [3+, 2-]$\n",
    "\n",
    "Como visto, o atributo Idade possui três valore e devemos calcular a entropia para cada um desses atributos: \n",
    "\n",
    "$E(S_{MENOR30}) = -\\frac{2}{5}\\log_2{\\frac{2}{5}} - \\frac{3}{5}\\log_2{\\frac{3}{5}} = 0.971$\n",
    "\n",
    "$E(S_{3140}) = 0$\n",
    "\n",
    "$E(S_{MAIOR40}) = -\\frac{3}{5}\\log_2{\\frac{3}{5}} - \\frac{2}{5}\\log_2{\\frac{2}{5}} = 0.971$\n",
    "\n",
    "Com isso podemos calcular: \n",
    "\n",
    "$- \\sum_{v \\in Valores(A)}{\\frac{S_v}{S}E(S_v)}$\n",
    "\n",
    "$- \\frac{5}{14}*0.971 - \\frac{4}{14}*0 - \\frac{5}{14}*0.971 = -0.693$\n",
    "\n",
    "Por fim, temos que  o Ganho de Informação é: \n",
    "\n",
    "$GI(S,A) = E(S) - \\sum_{v \\in Valores(A)}{\\frac{S_v}{S}E(S_v)} = 0.940 - 0.693 = 0.247$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sendo assim, temos:\n",
    "\n",
    "* Atributo Idade: GI = 0.247\n",
    "* Atributo Salário: GI = 0.03\n",
    "* Atributo SuperiorCompleto: GI = 0.152\n",
    "* Atributo Dependentes: GI = 0.016\n",
    "\n",
    "Logo, o melhor atributo para ser raiz da árvore é o atributo `Idade`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atividade 03\n",
    "\n",
    "Para esta ativididade vamos trabalhar com a base de dígitos disponibilizada pelo scikit-learn.\n",
    "\n",
    "Detalhes da base podem ser econtrados [neste link](http://archive.ics.uci.edu/ml/datasets/Pen-Based+Recognition+of+Handwritten+Digits).\n",
    "\n",
    "A tarefa é classificar um conjunto de imagens de acordo com o dígito que a imagem corresponde. As imagens foram coletadas a partir de dígitos escritos à mão. \n",
    "\n",
    "Tarefa:\n",
    "\n",
    "* Aplique o algoritmo de árvore de decisão e reporte o valor da acurácia \n",
    "* Aplique o algoritmo KNN e compare o modelo de KNN (com o melhor valor de k) com o modelo de árvore de decisão (variando também os valores necessários).\n",
    "* Em todos os testes utilize a validação cruzada com 5 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicando KNN para escolha do melhor valor de `k`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.9649752094799343\n",
      "2 0.9666281215002192\n",
      "3 0.9661143537042125\n",
      "4 0.9639057779662252\n",
      "5 0.9627899114966898\n",
      "6 0.9594189778290522\n",
      "7 0.9600006636118843\n",
      "8 0.9577720868648678\n",
      "9 0.9561253164543428\n",
      "10 0.9550157272024308\n",
      "11 0.9555621421134866\n",
      "12 0.9561099260379361\n",
      "13 0.9555511626324675\n",
      "14 0.9560991524977508\n",
      "15 0.9544338354787648\n",
      "16 0.9544509214030586\n",
      "17 0.9533120120025\n",
      "18 0.948874859517496\n",
      "19 0.9516358008896691\n",
      "20 0.9505368144035937\n",
      "21 0.948882476865627\n",
      "22 0.9499982579479882\n",
      "23 0.9483299906777816\n",
      "24 0.949461247563724\n",
      "25 0.9461061952977359\n",
      "26 0.945564517816561\n",
      "27 0.9449844572086453\n",
      "28 0.9427435256836165\n",
      "29 0.9405460148138225\n",
      "Best: 2: 0.966628\n"
     ]
    }
   ],
   "source": [
    "range_k = range(1, 30)\n",
    "\n",
    "best_acc = 0\n",
    "best_k = 0\n",
    "\n",
    "for k in range_k:\n",
    "    knn_ = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    score_ = cross_val_score(knn_, X, y, cv=5, scoring='accuracy')\n",
    "    \n",
    "    score_mean = score_.mean()\n",
    "    \n",
    "    if score_mean > best_acc:\n",
    "        best_k = k\n",
    "        best_acc = score_mean\n",
    "        \n",
    "    print(k, score_mean)\n",
    "\n",
    "print(\"Best: %i: %f\" % (best_k, best_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O melhor modelo usando KNN é quando `k` é igual a `2` e possui uma acurácia de `0.966628`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árvore de Decisão\n",
    "\n",
    "Vamos variar alguns parâmetros da árvore de decisão para tentar encontrar um modelo melhor que o primeiro encontrado. A lista completa de atributos está disponível [neste link](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html).\n",
    "\n",
    "O primeiro teste da árvore de decisão será utilizando os valores padrões. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf = DecisionTreeClassifier()\n",
    "tree_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Árvore de Decisão - Acc: 0.769245\n"
     ]
    }
   ],
   "source": [
    "score_ = cross_val_score(tree_clf, X, y, cv=5, scoring='accuracy')\n",
    "print(\"Árvore de Decisão - Acc: %f\" % score_.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos variar um dos parâmetros: \n",
    "\n",
    "```\n",
    "criterion : string, optional (default=”gini”)\n",
    "\n",
    "    The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “entropy” for the information gain.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Árvore de Decisão - Acc: 0.801313\n"
     ]
    }
   ],
   "source": [
    "tree_clf = DecisionTreeClassifier(criterion='entropy')\n",
    "score_ = cross_val_score(tree_clf, X, y, cv=5, scoring='accuracy')\n",
    "print(\"Árvore de Decisão - Acc: %f\" % score_.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O `information gain` como critério para separação dos nós gerou um modelo melhor do que o que utilizava `Gini Impurity`. Vamos usar esse atributo nos próximos exemplos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Árvore de Decisão - Acc: 0.810796\n"
     ]
    }
   ],
   "source": [
    "tree_clf = DecisionTreeClassifier(criterion='entropy', max_depth=22)\n",
    "score_ = cross_val_score(tree_clf, X, y, cv=5, scoring='accuracy')\n",
    "print(\"Árvore de Decisão - Acc: %f\" % score_.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: \n",
      "Depth 1 - Acc: 0.195339\n",
      "Depth 2 - Acc: 0.328135\n",
      "Depth 3 - Acc: 0.502474\n",
      "Depth 4 - Acc: 0.632277\n",
      "Depth 5 - Acc: 0.734772\n",
      "Depth 6 - Acc: 0.772502\n",
      "Depth 7 - Acc: 0.787070\n",
      "Depth 8 - Acc: 0.804730\n",
      "Depth 9 - Acc: 0.810308\n",
      "Depth 10 - Acc: 0.808056\n",
      "Depth 11 - Acc: 0.807547\n",
      "Depth 12 - Acc: 0.806413\n",
      "Depth 13 - Acc: 0.809741\n",
      "Depth 14 - Acc: 0.799244\n",
      "Depth 15 - Acc: 0.799716\n",
      "Depth 16 - Acc: 0.805803\n",
      "Depth 17 - Acc: 0.804124\n",
      "Depth 18 - Acc: 0.795367\n",
      "Depth 19 - Acc: 0.804731\n",
      "Depth 20 - Acc: 0.806829\n",
      "Depth 21 - Acc: 0.804756\n",
      "Depth 22 - Acc: 0.800163\n",
      "Depth 23 - Acc: 0.806922\n",
      "Depth 24 - Acc: 0.805299\n",
      "Depth 25 - Acc: 0.801434\n",
      "Depth 26 - Acc: 0.799165\n",
      "Depth 27 - Acc: 0.805904\n",
      "Depth 28 - Acc: 0.807603\n",
      "Depth 29 - Acc: 0.805223\n",
      "Depth 30 - Acc: 0.813089\n",
      "Depth 31 - Acc: 0.799210\n",
      "Depth 32 - Acc: 0.802494\n",
      "Depth 33 - Acc: 0.806405\n",
      "Depth 34 - Acc: 0.801458\n",
      "Depth 35 - Acc: 0.802454\n",
      "Depth 36 - Acc: 0.804759\n",
      "Depth 37 - Acc: 0.795249\n",
      "Depth 38 - Acc: 0.801347\n",
      "Depth 39 - Acc: 0.814702\n",
      "Depth 40 - Acc: 0.804675\n",
      "Depth 41 - Acc: 0.805919\n",
      "Depth 42 - Acc: 0.814198\n",
      "Depth 43 - Acc: 0.797503\n",
      "Depth 44 - Acc: 0.811410\n",
      "Depth 45 - Acc: 0.799239\n",
      "Depth 46 - Acc: 0.809718\n",
      "Depth 47 - Acc: 0.807524\n",
      "Depth 48 - Acc: 0.807488\n",
      "Depth 49 - Acc: 0.806304\n",
      "Depth 50 - Acc: 0.802511\n",
      "Best: 39: 0.814702\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "best_acc = 0\n",
    "best_depth = 0\n",
    "\n",
    "max_depths = np.linspace(1, 50, 50, endpoint=True)\n",
    "print(\"Decision Tree: \")\n",
    "for max_depth in max_depths:\n",
    "    tree_clf = DecisionTreeClassifier(criterion='entropy', max_depth=max_depth, random_state=int(max_depth))\n",
    "    score_ = cross_val_score(tree_clf, X, y, cv=5, scoring='accuracy')\n",
    "    \n",
    "    if score_.mean() > best_acc:\n",
    "        best_acc = score_.mean()\n",
    "        best_depth = max_depth\n",
    "    \n",
    "    print(\"Depth %i - Acc: %f\" % (max_depth, score_.mean()))\n",
    "    \n",
    "print(\"Best: %i: %f\" % (best_depth, best_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como foi visto no material de Árvore de Decisão a poda é um importante parâmetro que ajuda evitar `overfitting`. Vamos usar profundidade `39` que nos retornou uma acurácia de `0.814702`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tentamos variar `min_samples_splits` e `min_samples_leaf` mas não teve melhoria expressiva nos modelos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
